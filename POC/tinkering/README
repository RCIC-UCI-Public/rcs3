
if [ "x$TMPDIR" == "x" ]; then
   TMPDIR=$(pwd)
fi

DB=dfs4-bsg.db
JSONFILE=$TMPDIR/dfs4-bsg.json.gz
PATHINVENTORY=/dfs4/bsg
BASEDB=$(basename $DB)

# Sample to create lsjson 
if [ ! -f $JSONFILE ]; then
   echo "Creating lsjon inventory of $PATHINVENTORY. Storing in File $JSONFILE"
   (time rclone lsjson --exclude-from exclude-snaps --metadata --recursive $PATHINVENTORY | gzip -c --fast > $JSONFILE) &> $TMPDIR/$BASEDB-json.time 
fi

# Create a new DB if needed
if [ ! -f $DB ]; then
   ./createdb.py $DB
fi

# Ingesting lsjson output into a sqlite DB (DB should be on /dev/shm or on nvme)
echo "Ingesting $JSONFILE into $DB.  Monitor progress in $TMPDIR/${BASEDB}-ingest.out"
(time zcat $JSONFILE | ./filterjson.py $PATHINVENTORY | sqlite3 -cmd "PRAGMA journal_mode=memory; PRAGMA synchronous=off" $DB) &> $TMPDIR/${BASEDB}-ingest.out &


# Some interesting queries (If the data is large, like SOM, some of these queuries can take 1-2 minutes)
# find some counts
# 1. # of files
#    select count(*) from allfiles;
# 2. # of folders
#    select count(*) from folders;
# 3. Size and number of files in each top-level directory
#    select level1,sum(size) as bytes,count(*) as nfiles from allfiles group by level1;
# Dates are stored as Julian dates (real). Use datetime to format
# 4. Find the date of the newest file by mtime
#    select datetime(max(jmtime)) from allfiles;
# 5. Find the the date of the newest file by atime (accesstime)
#    select datetime(max(jatime)) from allfiles; 
